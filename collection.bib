@article{Accot2001,
abstract = {Interaction tasks on a computer screen can technically be scaled to a much larger or much smaller sized input control area by adjusting the input device's control gain or the control-display (C-D) ratio. However, human performance as a function of movement scale is not a well concluded topic. This study introduces a new task paradigm to study the scale effect in the framework of the steering law. The results confirmed a U-shaped performance-scale function and rejected straight-line or no-effect hypotheses in the literature. We found a significant scale effect in path steering performance, although its impact was less than that of the steering law's index of difficulty. We analyzed the scale effects in two plausible causes: movement joints shift and motor precision limitation. The theoretical implications of the scale effects to the validity of the steering law, and the practical implications of input device size and zooming functions are discussed in the paper.},
address = {New York, New York, USA},
author = {Accot, Johnny and Zhai, Shumin},
doi = {10.1145/365024.365027},
file = {:Users/antoine/Documents/mendeley{\_}library/Accot, Zhai - 2001 - Scale effects in steering law tasks.pdf:pdf},
isbn = {1581133278},
journal = {Proceedings of the SIGCHI conference on Human factors in computing systems - CHI '01},
keywords = {are equivalent in,does it take the,figure 1,same amount of time,scale,steering law difficulty but,the two circular tunnels,they differ in movement,to steer},
pages = {1--8},
publisher = {ACM Press},
title = {{Scale effects in steering law tasks}},
url = {http://portal.acm.org/citation.cfm?doid=365024.365027 http://dl.acm.org/citation.cfm?id=365027},
year = {2001}
}
@inproceedings{Alvina2016,
abstract = {Gesture-typing is an efficient, easy-to-learn, and errortolerant technique for entering text on software keyboards. Our goal is to "recycle" users' otherwise-unused gesture variation to create rich output under the users' control, without sacrificing accuracy. Experiment 1 reveals a high level of existing gesture variation, even for accurate text, and shows that users can consciously vary their gestures under different conditions. We designed an Expressive Keyboard for a smart phone which maps input gesture features identified in Experiment 1 to a continuous output parameter space, i.e. RGB color. Experiment 2 shows that users can consciously modify their gestures, while retaining accuracy, to generate specific colors as they gesture-type. Users are more successful when they focus on output characteristics (such as red) rather than input characteristics (such as curviness). We designed an app with a dynamic font engine that continuously interpolates between several typefaces, as well as controlling weight and random variation. Experiment 3 shows that, in the context of a more ecologically-valid conversation task, users enjoy generating multiple forms of rich output. We conclude with suggestions for how the Expressive Keyboard approach can enhance a wide variety of gesture recognition applications.},
address = {New York, New York, USA},
author = {Alvina, Jessalyn and Malloch, Joseph and Mackay, Wendy E.},
booktitle = {Proceedings of the 29th Annual Symposium on User Interface Software and Technology - UIST '16},
doi = {10.1145/2984511.2984560},
file = {:Users/antoine/Library/Application Support/Mendeley Desktop/Downloaded/Alvina, Malloch, Mackay - 2016 - Expressive Keyboards.pdf:pdf},
isbn = {9781450341899},
keywords = {continuous interaction,expressive communication,gesture input,gesture keyboard,mobile,text input},
pages = {583--593},
publisher = {ACM Press},
title = {{Expressive Keyboards: Enriching Gesture-Typing on Mobile Devices}},
url = {http://dl.acm.org/citation.cfm?doid=2984511.2984560},
year = {2016}
}
@inproceedings{Bachynskyi2015,
abstract = {Although different types of touch surfaces have gained extensive attention in HCI, this is the first work to directly compare them for two critical factors: performance and ergonomics. Our data come from a pointing task (N=40) carried out on five common touch surface types: public display (large, vertical, standing), tabletop (large, horizontal, seated), laptop (medium, adjustably tilted, seated), tablet (seated, in hand), and smartphone (single- and two-handed input). Ergonomics indices were calculated from biomechanical simulations of motion capture data combined with recordings of external forces. We provide an extensive dataset for researchers and report the first analyses of similarities and differences that are attributable to the different postures and movement ranges.},
address = {New York, New York, USA},
author = {Bachynskyi, Myroslav and Palmas, Gregorio and Oulasvirta, Antti and Steimle, J{\&}uuml;rgen and Weinkauf, Tino},
booktitle = {Proceedings of the ACM CHI'15 Conference on Human Factors in Computing Systems},
doi = {10.1145/2702123.2702607},
file = {:Users/antoine/Documents/mendeley{\_}library/Bachynskyi et al. - 2015 - Performance and Ergonomics of Touch Surfaces A Comparative Study using Biomechanical Simulation.pdf:pdf},
isbn = {978-1-4503-3145-6},
keywords = {Touchscreen surfaces, Biomechanical simulation, Fi},
month = {apr},
pages = {1817--1826},
publisher = {ACM Press},
title = {{Performance and Ergonomics of Touch Surfaces: A Comparative Study using Biomechanical Simulation}},
url = {http://dx.doi.org/10.1145/2702123.2702607},
volume = {1},
year = {2015}
}
@article{Buxton1990,
abstract = {A model to help characterize graphical input is presented. It is a refinement of a model first introduced by Buxton, Hill and Rowley (1985). The importance of the model is that it can characterize both many of the demands of interactive transactions, and many of the capabilities of input transducers. Hence, it provides a simple and usable means to aid finding a match between the two. After an introduction, an overview of approaches to categorizing input is presented. The model is then described and discussed in terms of a number of different input technologies and techniques.},
author = {Buxton, William A. S.},
isbn = {0444888179},
journal = {INTERACT '90 Proceedings of the IFIP TC13 Third Interational Conference on Human-Computer Interaction},
pages = {449--456},
title = {{a Three-State Model of Graphical Input}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.139.1700},
year = {1990}
}
@article{Casiez2008,
author = {Casiez, Gery and Vogel, Daniel and Balakrishnan, Ravin and Cockburn, Andy},
doi = {10.1080/07370020802278163},
file = {:Users/antoine/Desktop/The Impact of Control Display Gain on User Performance in Pointing Tasks.pdf:pdf},
issn = {0737-0024},
journal = {Human-Computer Interaction},
month = {jul},
number = {3},
pages = {215--250},
title = {{The Impact of Control-Display Gain on User Performance in Pointing Tasks}},
url = {http://www.tandfonline.com/doi/abs/10.1080/07370020802278163},
volume = {23},
year = {2008}
}
@inproceedings{Forlines2007,
abstract = {We investigate the differences – in terms of both quantitative performance and subjective preference – between direct-touch and mouse input for unimanual and bimanual tasks on tabletop displays. The results of two experiments show that for bimanual tasks performed on tabletops, users benefit from direct-touch input. However, our results also indicate that mouse input may be more appropriate for a single user working on tabletop tasks requiring only single-point interaction.},
address = {New York, New York, USA},
author = {Forlines, Clifton and Wigdor, Daniel and Shen, Chia and Balakrishnan, Ravin},
booktitle = {Proceedings of the SIGCHI conference on Human factors in computing systems - CHI '07},
doi = {10.1145/1240624.1240726},
file = {:Users/antoine/Documents/mendeley{\_}library/Forlines et al. - 2007 - Direct-touch vs. mouse input for tabletop displays.pdf:pdf},
isbn = {9781595935939},
issn = {10892680},
keywords = {bimanual input,direct-touch interfaces,multiple mice,tabletop computing},
month = {apr},
pages = {647},
pmid = {16537458},
publisher = {ACM Press},
title = {{Direct-touch vs. mouse input for tabletop displays}},
url = {http://portal.acm.org/citation.cfm?doid=1240624.1240726},
year = {2007}
}
@inproceedings{Gilliot2014,
address = {New York, New York, USA},
author = {Gilliot, J{\'{e}}r{\'{e}}mie and Casiez, G{\'{e}}ry and Roussel, Nicolas},
booktitle = {Proceedings of the 32nd annual ACM conference on Human factors in computing systems - CHI '14},
doi = {10.1145/2556288.2556997},
file = {:Users/antoine/Documents/mendeley{\_}library/Gilliot, Casiez, Roussel - 2014 - Impact of form factors and input conditions on absolute indirect-touch pointing tasks.pdf:pdf},
isbn = {9781450324731},
keywords = {absolute pointing,form factors,indirect touch,input conditions,performance},
pages = {723--732},
publisher = {ACM Press},
title = {{Impact of form factors and input conditions on absolute indirect-touch pointing tasks}},
url = {http://dl.acm.org/citation.cfm?doid=2556288.2556997},
year = {2014}
}
@inproceedings{Guiard1999,
address = {University of Edinburgh, Scotland},
author = {Guiard, Yves},
booktitle = {Proceedings of the Tenth International Conference on Perception and Action},
pages = {p. 87},
title = {{Difficulty and scale as the basic dimensions of aimed movement.}},
year = {1999}
}
@inproceedings{Harrison2011,
address = {New York, New York, USA},
author = {Harrison, Chris and Benko, Hrvoje and Wilson, Andrew D.},
booktitle = {Proceedings of the 24th annual ACM symposium on User interface software and technology - UIST '11},
doi = {10.1145/2047196.2047255},
file = {:Users/antoine/Documents/mendeley{\_}library/Harrison, Benko, Wilson - 2011 - OmniTouch.pdf:pdf},
isbn = {9781450307161},
keywords = {appropriated surfaces,finger tracking,object classification,on-body computing,on-demand interfaces},
month = {oct},
pages = {441},
publisher = {ACM Press},
title = {{OmniTouch}},
url = {http://dl.acm.org/citation.cfm?doid=2047196.2047255},
year = {2011}
}
@incollection{Hart1988,
author = {Hart, Sandra G. and Staveland, Lowell E.},
doi = {10.1016/S0166-4115(08)62386-9},
pages = {139--183},
title = {{Development of NASA-TLX (Task Load Index): Results of Empirical and Theoretical Research}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0166411508623869},
year = {1988}
}
@inproceedings{Kratz2013,
address = {New York, New York, USA},
author = {Kratz, Sven and Chiu, Patrick and Back, Maribeth},
booktitle = {Proceedings of the 2013 ACM international conference on Interactive tabletops and surfaces - ITS '13},
doi = {10.1145/2512349.2512824},
file = {:Users/antoine/Documents/mendeley{\_}library/Kratz, Chiu, Back - 2013 - PointPose.pdf:pdf},
isbn = {9781450322713},
keywords = {depth sensor,finger pose,mobile device,mobile interaction,point cloud,touch input},
month = {oct},
pages = {223--230},
publisher = {ACM Press},
title = {{PointPose}},
url = {http://dl.acm.org/citation.cfm?doid=2512349.2512824},
year = {2013}
}
@inproceedings{Kristensson2004,
address = {New York, New York, USA},
author = {Kristensson, Per-Ola and Zhai, Shumin},
booktitle = {Proceedings of the 17th annual ACM symposium on User interface software and technology  - UIST '04},
doi = {10.1145/1029632.1029640},
file = {:Users/antoine/Documents/mendeley{\_}library/Kristensson, Zhai - 2004 - SHARK sup2sup.pdf:pdf},
isbn = {1581139578},
keywords = {gesture recognition,shorthand,shorthand recognition,stenography,text input},
month = {oct},
pages = {43},
publisher = {ACM Press},
title = {{SHARK {\textless}sup{\textgreater}2{\textless}/sup{\textgreater}}},
url = {http://portal.acm.org/citation.cfm?doid=1029632.1029640},
year = {2004}
}
@article{Letessier2004,
abstract = {V isual tracking of bare fingers allows more direct manipu- lation of digital objects, multiple simultaneous users interacting with their two hands, and permits the interaction on large surfaces, using only commodity hardware. After presenting related work, we detail our implementation. Its design is based on our modeling of two classes of algorithms that are key to the tracker: Image Differencing Segmentation (IDS) and Fast Rejection Filters (FRF). We introduce a new chromatic distance for IDS and a FRF that is independent to finger rotation. The system runs at full frame rate (25 Hz) with an average total system latency of 80 ms, independently of the number of tracked fingers. When used in a controlled environment such as a meeting room, its robustness is satisfying for everyday use.},
address = {New York, New York, USA},
author = {Letessier, Julien and B{\'{e}}rard, Fran{\c{c}}ois},
doi = {10.1145/1029632.1029652},
file = {:Users/antoine/Documents/mendeley{\_}library/Letessier, B�rard - 2004 - Visual tracking of bare fingers for interactive surfaces.pdf:pdf},
isbn = {1581139578},
journal = {Proceedings of the 17th annual ACM symposium on User interface software and technology},
keywords = {fi nger tracking with computer vision,large interactive surface,multi-hand interaction},
pages = {119--122},
publisher = {ACM Press},
title = {{Visual tracking of bare fingers for interactive surfaces}},
url = {http://portal.acm.org/citation.cfm?doid=1029632.1029652 http://dl.acm.org/citation.cfm?id=1029652},
volume = {6},
year = {2004}
}
@inproceedings{Levesque2011,
address = {New York, New York, USA},
author = {Levesque, Vincent and Oram, Louise and MacLean, Karon and Cockburn, Andy and Marchuk, Nicholas D. and Johnson, Dan and Colgate, J. Edward and Peshkin, Michael A.},
booktitle = {Proceedings of the 2011 annual conference on Human factors in computing systems - CHI '11},
doi = {10.1145/1978942.1979306},
file = {:Users/antoine/Documents/mendeley{\_}library/Levesque et al. - 2011 - Enhancing physicality in touch interaction with programmable friction.pdf:pdf},
isbn = {9781450302289},
keywords = {Fitts Law,design space,haptics,programmable friction,tactile feedback,target acquisition,touch interaction,touch interface,touch screen,touchscreen,variable friction},
month = {may},
pages = {2481},
publisher = {ACM Press},
title = {{Enhancing physicality in touch interaction with programmable friction}},
url = {http://dl.acm.org/citation.cfm?id=1978942.1979306},
year = {2011}
}
@article{MacKenzie1992,
author = {MacKenzie, I. Scott and Scott, I.},
doi = {10.1207/s15327051hci0701_3},
file = {:Users/antoine/Library/Application Support/Mendeley Desktop/Downloaded/MacKenzie, Scott - 1992 - Fitts' Law as a Research and Design Tool in Human-Computer Interaction.pdf:pdf},
issn = {0737-0024},
journal = {Human?Computer Interaction},
month = {mar},
number = {1},
pages = {91--139},
publisher = {L. Erlbaum Associates Inc.},
title = {{Fitts' Law as a Research and Design Tool in Human-Computer Interaction}},
url = {http://www.tandfonline.com/doi/abs/10.1207/s15327051hci0701{\_}3},
volume = {7},
year = {1992}
}
@article{Markussen2014,
abstract = {Word-gesture keyboards enable fast text entry by letting users draw the shape of a word on the input surface. Such keyboards have been used extensively for touch devices, but not in mid-air, even though their fluent gestural input seems well suited for this modality. We present Vulture, a word-gesture keyboard for mid-air operation. Vulture adapts touch based word-gesture algorithms to work in mid-air, projects users' movement onto the display, and uses pinch as a word delimiter. A first 10-session study suggests text-entry rates of 20.6 Words Per Minute (WPM) and finds hand-movement speed to be the primary predictor of WPM. A second study shows that with training on a few phrases, participants do 28.1 WPM, 59{\%} of the text-entry rate of direct touch input. Participants' recall of trained gestures in mid-air was low, suggesting that visual feedback is important but also limits performance. Based on data from the studies, we discuss improvements to Vulture and some alternative designs for mid-air text entry.},
address = {New York, New York, USA},
author = {Markussen, Anders and Jakobsen, Mikkel R{\o}nne and Hornb{\ae}k, Kasper},
doi = {10.1145/2556288.2556964},
file = {:Users/antoine/Documents/mendeley{\_}library/Markussen et al. - 2014 - Vulture.pdf:pdf},
isbn = {9781450324731},
journal = {Proceedings of the 32nd annual ACM conference on Human factors in computing systems - CHI '14},
keywords = {freehand interaction,in-air interaction,mid-air interaction,shape writing,text entry,word-gesture keyboard},
pages = {1073--1082},
publisher = {ACM Press},
title = {{Vulture: a mid-air word-gesture keyboard}},
url = {http://dl.acm.org/citation.cfm?doid=2556288.2556964 http://dl.acm.org/citation.cfm?id=2611105.2556964},
year = {2014}
}
@inproceedings{McGregor2014,
abstract = {This report presents preliminary results from an unobtrusive video study of iPhone use – totalling over 100 days of everyday device usage. The data gives us a uniquely detailed view on how messages, social media and internet use are integrated and threaded into daily life, our interaction with others, and everyday events such as transport, communication and entertainment. These initial results seek to address the when, who and what of situated mobile phone use – beginning with understanding the impact of context. We then characterise three key modes of use found in the data: micro-breaks, digital knitting and reading. Finally we consider the multi-party and shared nature of phone use and who is involved. We reflect on analysis to date, designing from understanding use and future work – our data provides the resource and scope for further analysis of the moment-by-moment use of contemporary mobile phones. Author},
address = {New York, New York, USA},
author = {McGregor, Moira and Brown, Barry and McMillan, Donald},
booktitle = {Proceedings of the extended abstracts of the 32nd annual ACM conference on Human factors in computing systems - CHI EA '14},
doi = {10.1145/2559206.2581296},
file = {:Users/antoine/Documents/mendeley{\_}library/McGregor, Brown, McMillan - 2014 - 100 days of iPhone use.pdf:pdf},
isbn = {9781450324748},
keywords = {device use,iphone,screen recording,video analysis},
month = {sep},
pages = {2335--2340},
publisher = {ACM Press},
title = {{100 days of iPhone use}},
url = {http://dl.acm.org/citation.cfm?doid=2559206.2581296},
year = {2014}
}
@article{Quinn2016,
author = {Quinn, Philip and Zhai, Shumin},
doi = {10.1080/07370024.2016.1215922},
issn = {0737-0024},
journal = {Human–Computer Interaction},
month = {aug},
pages = {1--47},
title = {{Modeling Gesture-Typing Movements}},
url = {https://www.tandfonline.com/doi/full/10.1080/07370024.2016.1215922},
year = {2016}
}
@incollection{Schmidt2009,
author = {Schmidt, Dominik and Block, Florian and Gellersen, Hans},
booktitle = {Proceedings of the 12th IFIP TC 13 International Conference on Human-Computer Interaction: Part I},
doi = {10.1007/978-3-642-03655-2_65},
file = {:Users/antoine/Desktop/40817497305cdb0ddd3218b9f31e9bb64586.pdf:pdf},
isbn = {978-3-642-03654-5},
keywords = {Multi-touch interfaces,indirect input,surface computing},
pages = {582--594},
publisher = {Springer-Verlag},
title = {{A Comparison of Direct and Indirect Multi-touch Input for Large Surfaces}},
url = {http://link.springer.com/10.1007/978-3-642-03655-2{\_}65},
year = {2009}
}
@inproceedings{Sridhar2017,
address = {New York, New York, USA},
author = {Sridhar, Srinath and Markussen, Anders and Oulasvirta, Antti and Theobalt, Christian and Boring, Sebastian},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems  - CHI '17},
doi = {10.1145/3025453.3026005},
file = {:Users/antoine/Library/Application Support/Mendeley Desktop/Downloaded/Sridhar et al. - 2017 - WatchSense.pdf:pdf},
isbn = {9781450346559},
keywords = {depth sensor,finger tracking,skin interaction,smartwatch},
pages = {3891--3902},
publisher = {ACM Press},
title = {{WatchSense}},
url = {http://dl.acm.org/citation.cfm?doid=3025453.3026005},
year = {2017}
}
@inproceedings{Sridhar2015,
author = {Sridhar, Srinath and Mueller, Franziska and Oulasvirta, Antti and Theobalt, Christian},
booktitle = {Computer Vision and Pattern Recognition (CVPR), 2015},
file = {:Users/antoine/Documents/mendeley{\_}library/Sridhar et al. - 2015 - Fast and Robust Hand Tracking Using Detection-Guided Optimization.pdf:pdf},
title = {{Fast and Robust Hand Tracking Using Detection-Guided Optimization}},
url = {http://handtracker.mpi-inf.mpg.de/projects/FastHandTracker/},
year = {2015}
}
@article{Taylor2016,
author = {Taylor, Jonathan and Luff, Benjamin and Topalian, Arran and Wood, Erroll and Khamis, Sameh and Kohli, Pushmeet and Izadi, Shahram and Banks, Richard and Fitzgibbon, Andrew and Shotton, Jamie and Bordeaux, Lucas and Cashman, Thomas and Corish, Bob and Keskin, Cem and Sharp, Toby and Soto, Eduardo and Sweeney, David and Valentin, Julien},
doi = {10.1145/2897824.2925965},
file = {:Users/antoine/Library/Application Support/Mendeley Desktop/Downloaded/Taylor et al. - 2016 - Efficient and precise interactive hand tracking through joint, continuous optimization of pose and correspondence.pdf:pdf},
issn = {07300301},
journal = {ACM Transactions on Graphics},
keywords = {articulated tracking,subdivision surfaces,virtual reality},
month = {jul},
number = {4},
pages = {1--12},
publisher = {ACM},
title = {{Efficient and precise interactive hand tracking through joint, continuous optimization of pose and correspondences}},
url = {http://dl.acm.org/citation.cfm?doid=2897824.2925965},
volume = {35},
year = {2016}
}
@inproceedings{Vertanen2015,
address = {New York, New York, USA},
author = {Vertanen, Keith and Memmi, Haythem and Emge, Justin and Reyal, Shyam and Kristensson, Per Ola},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems - CHI '15},
doi = {10.1145/2702123.2702135},
file = {:Users/antoine/Documents/mendeley{\_}library/Vertanen et al. - 2015 - VelociTap.pdf:pdf},
isbn = {9781450331456},
keywords = {mobile text entry,sentence decoding,touchscreen keyboard},
pages = {659--668},
publisher = {ACM Press},
title = {{VelociTap}},
url = {http://dl.acm.org/citation.cfm?doid=2702123.2702135},
year = {2015}
}
@inproceedings{Wen2016,
address = {New York, New York, USA},
author = {Wen, Elliott and Seah, Winston and Ng, Bryan and Liu, Xuefeng and Cao, Jiannong},
booktitle = {Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing - UbiComp '16},
doi = {10.1145/2971648.2971678},
file = {:Users/antoine/Library/Application Support/Mendeley Desktop/Downloaded/Wen et al. - 2016 - UbiTouch.pdf:pdf},
isbn = {9781450344616},
pages = {286--297},
publisher = {ACM Press},
title = {{UbiTouch}},
url = {http://dl.acm.org/citation.cfm?doid=2971648.2971678},
year = {2016}
}
@inproceedings{Wigdor2006,
address = {New York, New York, USA},
author = {Wigdor, Daniel and Shen, Chia and Forlines, Clifton and Balakrishnan, Ravin},
booktitle = {Proceedings of the SIGCHI conference on Human Factors in computing systems  - CHI '06},
doi = {10.1145/1124772.1124819},
file = {:Users/antoine/Library/Application Support/Mendeley Desktop/Downloaded/Wigdor et al. - 2006 - Effects of display position and control space orientation on user preference and performance.pdf:pdf},
isbn = {1595933727},
keywords = {display position,input control space orientation,input-output mappings,performance,spatial transformation},
pages = {309},
publisher = {ACM Press},
title = {{Effects of display position and control space orientation on user preference and performance}},
url = {http://portal.acm.org/citation.cfm?doid=1124772.1124819},
year = {2006}
}
@inproceedings{Wilson2010,
abstract = {Abstract We explore the application of depth -sensing cameras to detect touch on a tabletop. Limits of depth estimate resolution and line of sight requirements dictate that the determination of the moment of touch will not be as precise as that of more direct sensing ... $\backslash$n},
address = {New York, New York, USA},
author = {Wilson, Andrew D.},
booktitle = {Proceedings of ITS 2010},
doi = {10.1145/1936652.1936665},
file = {:Users/antoine/Documents/mendeley{\_}library/Wilson - 2010 - Using a depth camera as a touch sensor.pdf:pdf},
isbn = {9781450303996},
issn = {978-1-4503-0399-6},
keywords = {depth-sensing cameras,touchscreen interfaces},
month = {nov},
pages = {69--72},
publisher = {ACM Press},
title = {{Using a depth camera as a touch sensor}},
url = {http://dl.acm.org/citation.cfm?id=1936665{\%}5Cnpapers://c80d98e4-9a96-4487-8d06-8e1acc780d86/Paper/p10467},
year = {2010}
}
@inproceedings{Xiao2016,
address = {New York, New York, USA},
author = {Xiao, Robert and Hudson, Scott and Harrison, Chris},
booktitle = {Proceedings of the 2016 ACM on Interactive Surfaces and Spaces  - ISS '16},
doi = {10.1145/2992154.2992173},
file = {:Users/antoine/Documents/mendeley{\_}library/Xiao, Hudson, Harrison - 2016 - DIRECT.pdf:pdf},
isbn = {9781450342483},
keywords = {depth sensing,sensor fusion,touch tracking},
pages = {85--94},
publisher = {ACM Press},
title = {{DIRECT}},
url = {http://dl.acm.org/citation.cfm?doid=2992154.2992173},
year = {2016}
}
